<!DOCTYPE html>
<html>

<head>
<title> Yu Sun </title>
</head>

<body style="font-size: 125%;">

<img src="img/profile.jpg" alt="Photo" height="300">

<h1>Yu Sun</h1>
<p>Email: ys646 [at] stanford.edu</p>

<p>
I'm a postdoc at Stanford University, hosted by Carlos Guestrin, Tatsu Hashimoto, and Sanmi Koyejo.
I'm also a researcher at NVIDIA under Yejin Choi.
My research focuses on continual learning, specifically a conceptual framework called test-time training, where each test instance defines its own learning problem.
I completed my PhD in 2023 at UC Berkeley, advised by Alyosha Efros and Moritz Hardt. 
My PhD thesis is 
<a href="https://www2.eecs.berkeley.edu/Pubs/TechRpts/2023/EECS-2023-86.html
"><i>Test-Time Training</i></a>.
During my undergrad at Cornell University, I worked with Kilian Weinberger.
</p>

<h3>My Research</h3>

<p>
Humans are able to continuously learn throughout their lives. 
But most of today's AI systems remain static after deployment, even though the world keeps changing. 
The high-level goal of my research is to enable AI systems to continuously learn like humans.
</p>

<p>
Specifically, human continual learning stands out in two important aspects.
First, each person has a unique brain that learns within the context of their individual life.
This personalized form of continual learning is quite different from, for example, a chatbot model that is fine-tuned hourly using the latest information available worldwide.
While such a model does change over time, it is still the same at any given moment for every user and every problem instance.
</p>

<p>
Second, most human learning happens without a boundary between training and testing.
Consider your commute to work this morning. It is both "testing" because you did care about getting to work this very morning, and "training" because you were also gaining experience for future commutes.
But in machine learning, the train-test split has always been a fundamental concept, often taught in the first lecture of an introductory course as:
"Do not train on the test set!"
</p>

<p>
I believe that these two special aspects of human learning are intimately connected and should be studied together in the field of AI.
In particular, continual learning will be most powerful when it targets the specific problem instance that we care about, conventionally known as the test instance.
Guided by this belief, I have been developing a conceptual framework known as test-time training since 2019, to focus on these two aspects that were missing from the continual learning literature.
The best way to learn more about the technical aspects of my research is to look at the selected papers below.
</p>

<h3>Selected Papers</h3>

<p>
For a complete list of papers, please see my 
<a href="https://scholar.google.com/citations?user=a7drwRMAAAAJ&hl=en&oi=ao">Google Scholar</a>.
</p>

<p>
* indicates equal contribution.
</p>
<p><b>Learning to (Learn at Test Time): RNNs with Expressive Hidden States</b><br>
Yu Sun*, Xinhao Li*, Karan Dalal*, Jiarui Xu, Arjun Vikram, Genghan Zhang, Yann Dubois,
Xinlei Chen†, Xiaolong Wang†, Sanmi Koyejo†, Tatsunori Hashimoto†, Carlos Guestrin†<br>
ICML 2025<br>
[<a href="https://arxiv.org/abs/2407.04620">paper</a>]
[<a href="https://github.com/test-time-training/ttt-lm-jax">JAX code</a>]
[<a href="https://github.com/test-time-training/ttt-lm-pytorch">PyTorch code</a>]
</p>

<!-- <p><b>Test-Time Training on Nearest Neighbors for Large Language Models</b><br>
Moritz Hardt, Yu Sun<br>
ICLR 2024<br>
[<a href="https://arxiv.org/abs/2305.18466">paper</a>]
[<a href="https://github.com/socialfoundations/tttlm">code</a>]
</p> -->

<p><b>Test-Time Training on Video Streams</b><br>
Renhao Wang*, Yu Sun*, Arnuv Tandon, Yossi Gandelsman, Xinlei Chen, Alexei A. Efros, Xiaolong Wang<br>
JMLR<br>
[<a href="https://arxiv.org/abs/2307.05014">paper</a>]
[<a href="https://test-time-training.github.io/video">website</a>]
</p>

<p><b>Test-Time Training with Masked Autoencoders</b><br>
Yossi Gandelsman*, Yu Sun*, Xinlei Chen, Alexei A. Efros<br>
NeurIPS 2022<br>
[<a href="https://arxiv.org/abs/2209.07522">paper</a>]
[<a href="https://yossigandelsman.github.io/ttt_mae/index.html">website</a>]
<!-- [<a href="https://youtu.be/NbuWxmMco30">talk</a>] -->
</p>

<p><b>Test-Time Training with Self-Supervision for Generalization under Distribution Shifts</b><br>
Yu Sun, Xiaolong Wang, Zhuang Liu, John Miller, Alexei A. Efros, Moritz Hardt<br>
ICML 2020<br>
[<a href="https://arxiv.org/abs/1909.13231">paper</a>]
[<a href="ttt/home.html">website</a>]
[<a href="https://youtu.be/NbuWxmMco30">talk</a>]
</p>

<!-- <h3>Older Papers</h3>

<p>
* indicates alphabetical order.
</p>

<p><b>On Calibration of Modern Neural Networks</b><br>
Chuan Guo*, Geoff Pleiss*, Yu Sun*, Kilian Q. Weinberger<br>
ICML 2017<br> 
[<a href="https://arxiv.org/abs/1706.04599">paper</a>]
[<a href="https://github.com/gpleiss/temperature_scaling">code</a>]
</p>

<p><b>Deep Networks with Stochastic Depth</b><br>
Gao Huang*, Yu Sun*, Zhuang Liu, Daniel Sedra, Kilian Q. Weinberger<br>
ECCV 2016<br> 
[<a href="https://arxiv.org/abs/1603.09382">paper</a>]
[<a href="https://github.com/yueatsprograms/Stochastic_Depth">code</a>]
[<a href="https://videolectures.net/eccv2016_sun_deep_networks/">talk</a>]
</p>

<p><b>From Word Embeddings To Document Distances</b><br>
Matt Kusner, Yu Sun, Nicholas Kolkin, Kilian Q. Weinberger<br>
ICML 2015<br> 
[<a href="https://proceedings.mlr.press/v37/kusnerb15.pdf">paper</a>]
</p> -->

</body>
</html>