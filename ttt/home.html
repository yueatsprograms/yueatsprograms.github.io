<!DOCTYPE html>
<html lang="en">
  <head>
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <title> Test-Time Training Project Website </title>

    <script src="https://polyfill.io/v3/polyfill.min.js?features=es6">
    </script>
    <script id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js">
    </script>
    
    <link href="../lib/css/bootstrap.min.css" rel="stylesheet">

    <style>
      body {
        font-family:Arial;
        font-size:20px;
        margin:60px auto;
        width:auto;
        max-width:900px;
      }

      hr {
        border:0;
        height:1.0px;
        background-image:linear-gradient(to right, rgba(0, 0, 0, 0.3), rgba(0, 0, 0, 0.3), rgba(0, 0, 0, 0.3));
      }

      .gap-30 {
      width:100%;
      height:30px;
      }

      .gap-20 {
      width:100%;
      height:20px;
      }

      .gap-10 {
      width:100%;
      height:10px;
      }

      .gap-5 {
      width:100%;
      height:5px;
      }
    </style>
  </head>

  <div class="container">
  <body>

    <!--------------------- title --------------------->
    <div class="gap-20"></div>
    <center><span style="font-size:40px">
      Test-Time Training with Self-Supervision for Generalization under Distribution Shifts 
    </span></center>
    <div class="gap-20"></div>

    <!---------------------  authors --------------------->
    <span style="font-size:20px">
          &nbsp;
          <div style="display:inline-block">
          <a href="https://yueatsprograms.github.io">Yu Sun</a>
          <sup style="font-size:15px">1</sup>,
          </div>
          &nbsp;
          <div style="display:inline-block">
          <a href="https://xiaolonw.github.io">Xiaolong Wang</a>
          <sup style="font-size:15px">12</sup>,
          </div>
          &nbsp;
          <div style="display:inline-block">
          <a href="https://liuzhuang13.github.io/">Zhuang Liu</a>
          <sup style="font-size:15px">1</sup>,
          </div>
          &nbsp;
          <div style="display:inline-block">
          <a href="https://people.eecs.berkeley.edu/~miller_john/">John Miller</a>
          <sup style="font-size:15px">1</sup>,
          </div>
          &nbsp;
          <div style="display:inline-block">
          <a href="https://people.eecs.berkeley.edu/~efros/">Alexei A. Efros</a>
          <sup style="font-size:15px">1</sup>,
          </div>
          &nbsp;
          <div style="display:inline-block">
          <a href="https://mrtz.org/">Moritz Hardt</a>
          <sup style="font-size:15px">1</sup>
          </div>
    </span>

    <!--------------------- affiliations --------------------->
    <div class="gap-5"></div>
    <div class="row">
      <div class="col-md-3"></div>
      <div class="col-md-3">
        <center><span style="font-size:20px">
          UC Berkeley<sup style="font-size:15px">1</sup>
        </span></center>
      </div>
      <div class="col-md-3">
        <center><span style="font-size:20px">
          UC San Diego<sup style="font-size:15px">2</sup>
        </span></center>
      </div>
      <div class="col-md-3"></div>
    </div>
    <hr>

    <!--------------------- links --------------------->
    <div class="gap-40"></div>
    <center>
    <span style="font-size:20px"> 
      Our latest work at NeurIPS 2022: 
      <a href="https://yossigandelsman.github.io/ttt_mae/index.html">Test-Time Training with Masked Autoencoders</a>
    </span>
    <div class="gap-40"></div>
    <hr>

    <div class="gap-10"></div>
    <center>
    <span style="font-size:20px"> 
      ICML 2020
      &nbsp; 
      [<a href="https://arxiv.org/abs/1909.13231">paper</a>]
      &nbsp;
      [<a href="https://www.youtube.com/watch?v=NbuWxmMco30">talk</a>]
      &nbsp; 
      [<a href="slides.pdf">slides</a>]
      &nbsp; 
      [<a href="bibtex.txt">BibTeX</a>]
      &nbsp; 
      [<a href="https://github.com/yueatsprograms/ttt_cifar_release">code part 1</a>]
      &nbsp; 
      [<a href="https://github.com/yueatsprograms/ttt_imagenet_release">code part 2</a>]
    </span>
    <div class="gap-20"></div>

    <!--------------------- video --------------------->
    <iframe width="665" height="375" src="https://www.youtube.com/embed/NbuWxmMco30" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>
    </center>

    <!--------------------- abstract --------------------->
    <div class="gap-20"></div>
    <b><span style="font-size:25px">Abstract</span></b><br>
    <div class="gap-10"></div>
    <p> 
    In this paper, we propose Test-Time Training, a general approach for improving the performance of predictive models when training and test data come from different distributions. We turn a single unlabeled test sample into a self-supervised learning problem, on which we update the model parameters before making a prediction. This also extends naturally to data in an online stream. Our simple approach leads to improvements on diverse image classification benchmarks aimed at evaluating robustness to distribution shifts.
    </p>

    <hr>

    <!--------------------- content --------------------->
    <div class="gap-10"></div>
    <b><span style="font-size:25px">Introduction</span></b><br>
    <div class="gap-10"></div>
    <div class="gap-5"></div>
    <div class="img" style="text-align:center">
      <img src="teaser.png" style="margin:0.2em;max-width:70%">
    </div>
    <div class="gap-10"></div>
    <p> 
    Given model parameters \(\theta\) and a loss function \(\ell\), the standard test error is evaluated as the expected loss on a test distribution \(Q\).
    Test-Time Training modifies the expected loss and allows \(\theta\) to depend on the test input \(x\), without looking at the label \(y\).
    </p>
    <hr>

    <div class="gap-10"></div>
    <b><span style="font-size:25px">Method</span></b><br>
    <div class="img" style="text-align:center">
      <img src="method.png" style="margin:0.2em;max-width:100%">
    </div>
    <div class="gap-20"></div>
    <p>
    We use self-supervision to create label from unlabeled input. The form of self-supervision used here is rotation prediction <a href="https://arxiv.org/abs/1803.07728">(Gidaris et al. 2018)</a>, which rotates an input image by multiples of 90<span>&#176;</span>, and asks a model to solve the four-way classification problem. 
    Our model has both a self-supervised head \( \theta_s \) and a main task head \( \theta_m \), on top of a shared feature extractor \( \theta_e \). 
    </p>
    <p>
    At training time, we jointly optimize the self-supervised loss \( \ell_s \) and the main task loss \( \ell_m \) over the training distribution \(P\), where the main task label \(y\) is available.
    At test time, we cannot see the main task label, but we can still optimize the self-supervised loss over the single test input drawn from \(Q\) (grayed out because this expectation can be noisy). This produces \(\theta(x)\), which we then use to make a prediction on \(x\).
    </p>

    <div class="gap-10"></div>
    <img src="versions.png" style="margin:0em;max-width:100%">
    <div class="gap-20"></div>

    <p>
    If samples arrive in an online stream, the online version of our method keeps the state of the parameters across samples. While the standard version follows the standard setting of supervised learning,
    the online version makes the additional assumption that samples are produced by the same or smoothly changing distribution shifts.
    </p>
    <hr>

    <div class="gap-10"></div>
    <b><span style="font-size:25px">Results</span></b><br>
    <div class="gap-20"></div>

    <img src="histograms.png" style="margin:0em;max-width:100%">
    <div class="gap-20"></div>
    <p>
    We experiment on CIFAR-10-C
    <a href="https://arxiv.org/abs/1903.12261"> (Hendrycks et al. 2019)</a>,
    a standard object recognition benchmark that evaluates generalization across 15 types of corruptions.
    Test-Time Training (TTT) standard version makes significant improvements over the two baselines without hurting on the original distribution. The online version makes even more improvements. 
    </p>

    <div class="gap-10"></div>
    <img src="curves.png" style="margin:0em;max-width:100%">
    <div class="gap-20"></div>
    <p>
    We plot the accuracy of the online version as it progresses through test sets in ImageNet-C, the counterpart of CIFAR-10-C for ImageNet.
    Online TTT generalizes better as more samples are evaluated (x-axis), without hurting on the original distribution.
    </p>

    <p> 
    For more results on more benchmarks, please take a look at our full
    <a href="https://arxiv.org/abs/1909.13231">paper</a>.
    </p>

    <hr>
    <div class="gap-10"></div>
    <b><span style="font-size:25px">Discussion</span></b><br>
    <div class="gap-10"></div>
    <p> 
    In the end, we hope this paper can encourage researchers to abandon the self-imposed constraint of a fixed decision boundary for testing, or even the artificial division between training and testing altogether. 
    Our work is but a small step toward a new paradigm where much of the learning happens after a model is deployed.
    </p>

    <hr>

    <div class="gap-10"></div>
    <b><span style="font-size:25px">Acknowledgements</span></b><br>
    <div class="gap-10"></div>
    <p> 
    This work is supported by NSF grant 1764033, DARPA and Berkeley DeepDrive.
    This paper took a long time to develop, and benefited from conversations with many of our colleagues, including
    Ben Recht and his students Ludwig Schmidt, Vaishaal Shanker and Becca Roelofs;
    Ravi Teja Mullapudi, Achal Dave and Deva Ramanan;
    and Armin Askari, Allan Jabri, Ashish Kumar,
    Angjoo Kanazawa and Jitendra Malik.
    </p>

    <hr>
    Correspondance to yusun [at] berkeley [dot] edu.


  </body>
  </div>

  <!-- jQuery (necessary for Bootstrap's JavaScript plugins) -->
  <script src="https://ajax.googleapis.com/ajax/libs/jquery/1.12.4/jquery.min.js"></script>
  <!-- Include all compiled plugins (below), or include individual files as needed -->
  <script src="res/js/bootstrap.min.js"></script>

</html>

